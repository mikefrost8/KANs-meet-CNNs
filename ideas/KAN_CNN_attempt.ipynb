{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import yaml\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import importlib\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KANLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    KANLayer class\n",
    "    \n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "        in_dim: int\n",
    "            input dimension\n",
    "        out_dim: int\n",
    "            output dimension\n",
    "        size: int\n",
    "            the number of splines = input dimension * output dimension\n",
    "        k: int\n",
    "            the piecewise polynomial order of splines\n",
    "        grid: 2D torch.float\n",
    "            grid points\n",
    "        noises: 2D torch.float\n",
    "            injected noises to splines at initialization (to break degeneracy)\n",
    "        coef: 2D torch.tensor\n",
    "            coefficients of B-spline bases\n",
    "        scale_base: 1D torch.float\n",
    "            magnitude of the residual function b(x)\n",
    "        scale_sp: 1D torch.float\n",
    "            mangitude of the spline function spline(x)\n",
    "        base_fun: fun\n",
    "            residual function b(x)\n",
    "        mask: 1D torch.float\n",
    "            mask of spline functions. setting some element of the mask to zero means setting the corresponding activation to zero function.\n",
    "        grid_eps: float in [0,1]\n",
    "            a hyperparameter used in update_grid_from_samples. When grid_eps = 0, the grid is uniform; when grid_eps = 1, the grid is partitioned using percentiles of samples. 0 < grid_eps < 1 interpolates between the two extremes.\n",
    "        weight_sharing: 1D tensor int\n",
    "            allow spline activations to share parameters\n",
    "        lock_counter: int\n",
    "            counter how many activation functions are locked (weight sharing)\n",
    "        lock_id: 1D torch.int\n",
    "            the id of activation functions that are locked\n",
    "        device: str\n",
    "            device\n",
    "    \n",
    "    Methods:\n",
    "    --------\n",
    "        __init__():\n",
    "            initialize a KANLayer\n",
    "        forward():\n",
    "            forward \n",
    "        update_grid_from_samples():\n",
    "            update grids based on samples' incoming activations\n",
    "        initialize_grid_from_parent():\n",
    "            initialize grids from another model\n",
    "        get_subset():\n",
    "            get subset of the KANLayer (used for pruning)\n",
    "        lock():\n",
    "            lock several activation functions to share parameters\n",
    "        unlock():\n",
    "            unlock already locked activation functions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_dim=3, out_dim=2, num=5, k=3, noise_scale=0.1, scale_base=1.0, scale_sp=1.0, base_fun=torch.nn.SiLU(), grid_eps=0.02, grid_range=[-1, 1], sp_trainable=True, sb_trainable=True, device='cpu'):\n",
    "        ''''\n",
    "        initialize a KANLayer\n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "            in_dim : int\n",
    "                input dimension. Default: 2.\n",
    "            out_dim : int\n",
    "                output dimension. Default: 3.\n",
    "            num : int\n",
    "                the number of grid intervals = G. Default: 5.\n",
    "            k : int\n",
    "                the order of piecewise polynomial. Default: 3.\n",
    "            noise_scale : float\n",
    "                the scale of noise injected at initialization. Default: 0.1.\n",
    "            scale_base : float\n",
    "                the scale of the residual function b(x). Default: 1.0.\n",
    "            scale_sp : float\n",
    "                the scale of the base function spline(x). Default: 1.0.\n",
    "            base_fun : function\n",
    "                residual function b(x). Default: torch.nn.SiLU()\n",
    "            grid_eps : float\n",
    "                When grid_eps = 0, the grid is uniform; when grid_eps = 1, the grid is partitioned using percentiles of samples. 0 < grid_eps < 1 interpolates between the two extremes. Default: 0.02.\n",
    "            grid_range : list/np.array of shape (2,)\n",
    "                setting the range of grids. Default: [-1,1].\n",
    "            sp_trainable : bool\n",
    "                If true, scale_sp is trainable. Default: True.\n",
    "            sb_trainable : bool\n",
    "                If true, scale_base is trainable. Default: True.\n",
    "            device : str\n",
    "                device\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "            self\n",
    "            \n",
    "        Example\n",
    "        -------\n",
    "        >>> model = KANLayer(in_dim=3, out_dim=5)\n",
    "        >>> (model.in_dim, model.out_dim)\n",
    "        (3, 5)\n",
    "        '''\n",
    "        super(KANLayer, self).__init__()\n",
    "        # size \n",
    "        self.size = size = out_dim * in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.in_dim = in_dim\n",
    "        self.num = num\n",
    "        self.k = k\n",
    "\n",
    "        # shape: (size, num)\n",
    "        self.grid = torch.einsum('i,j->ij', torch.ones(size, device=device), torch.linspace(grid_range[0], grid_range[1], steps=num + 1, device=device))\n",
    "        self.grid = torch.nn.Parameter(self.grid).requires_grad_(False)\n",
    "        noises = (torch.rand(size, self.grid.shape[1]) - 1 / 2) * noise_scale / num\n",
    "        noises = noises.to(device)\n",
    "        # shape: (size, coef)\n",
    "        self.coef = torch.nn.Parameter(curve2coef(self.grid, noises, self.grid, k, device))\n",
    "        if isinstance(scale_base, float):\n",
    "            self.scale_base = torch.nn.Parameter(torch.ones(size, device=device) * scale_base).requires_grad_(sb_trainable)  # make scale trainable\n",
    "        else:\n",
    "            self.scale_base = torch.nn.Parameter(torch.FloatTensor(scale_base).to(device)).requires_grad_(sb_trainable)\n",
    "        self.scale_sp = torch.nn.Parameter(torch.ones(size, device=device) * scale_sp).requires_grad_(sp_trainable)  # make scale trainable\n",
    "        self.base_fun = base_fun\n",
    "\n",
    "        self.mask = torch.nn.Parameter(torch.ones(size, device=device)).requires_grad_(False)\n",
    "        self.grid_eps = grid_eps\n",
    "        self.weight_sharing = torch.arange(size)\n",
    "        self.lock_counter = 0\n",
    "        self.lock_id = torch.zeros(size)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        KANLayer forward given input x\n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "            x : 2D torch.float\n",
    "                inputs, shape (number of samples, input dimension)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "            y : 2D torch.float\n",
    "                outputs, shape (number of samples, output dimension)\n",
    "            preacts : 3D torch.float\n",
    "                fan out x into activations, shape (number of sampels, output dimension, input dimension)\n",
    "            postacts : 3D torch.float\n",
    "                the outputs of activation functions with preacts as inputs\n",
    "            postspline : 3D torch.float\n",
    "                the outputs of spline functions with preacts as inputs\n",
    "        \n",
    "        Example\n",
    "        -------\n",
    "        >>> model = KANLayer(in_dim=3, out_dim=5)\n",
    "        >>> x = torch.normal(0,1,size=(100,3))\n",
    "        >>> y, preacts, postacts, postspline = model(x)\n",
    "        >>> y.shape, preacts.shape, postacts.shape, postspline.shape\n",
    "        (torch.Size([100, 5]),\n",
    "         torch.Size([100, 5, 3]),\n",
    "         torch.Size([100, 5, 3]),\n",
    "         torch.Size([100, 5, 3]))\n",
    "        '''\n",
    "        batch = x.shape[0]\n",
    "        # x: shape (batch, in_dim) => shape (size, batch) (size = out_dim * in_dim)\n",
    "        x = torch.einsum('ij,k->ikj', x, torch.ones(self.out_dim, device=self.device)).reshape(batch, self.size).permute(1, 0)\n",
    "        preacts = x.permute(1, 0).clone().reshape(batch, self.out_dim, self.in_dim)\n",
    "        base = self.base_fun(x).permute(1, 0)  # shape (batch, size)\n",
    "        y = coef2curve(x_eval=x, grid=self.grid[self.weight_sharing], coef=self.coef[self.weight_sharing], k=self.k, device=self.device)  # shape (size, batch)\n",
    "        y = y.permute(1, 0)  # shape (batch, size)\n",
    "        postspline = y.clone().reshape(batch, self.out_dim, self.in_dim)\n",
    "        y = self.scale_base.unsqueeze(dim=0) * base + self.scale_sp.unsqueeze(dim=0) * y\n",
    "        y = self.mask[None, :] * y\n",
    "        postacts = y.clone().reshape(batch, self.out_dim, self.in_dim)\n",
    "        y = torch.sum(y.reshape(batch, self.out_dim, self.in_dim), dim=2)  # shape (batch, out_dim)\n",
    "        # y shape: (batch, out_dim); preacts shape: (batch, in_dim, out_dim)\n",
    "        # postspline shape: (batch, in_dim, out_dim); postacts: (batch, in_dim, out_dim)\n",
    "        # postspline is for extension; postacts is for visualization\n",
    "        return y, preacts, postacts, postspline\n",
    "\n",
    "    def update_grid_from_samples(self, x):\n",
    "        '''\n",
    "        update grid from samples\n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "            x : 2D torch.float\n",
    "                inputs, shape (number of samples, input dimension)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "            None\n",
    "        \n",
    "        Example\n",
    "        -------\n",
    "        >>> model = KANLayer(in_dim=1, out_dim=1, num=5, k=3)\n",
    "        >>> print(model.grid.data)\n",
    "        >>> x = torch.linspace(-3,3,steps=100)[:,None]\n",
    "        >>> model.update_grid_from_samples(x)\n",
    "        >>> print(model.grid.data)\n",
    "        tensor([[-1.0000, -0.6000, -0.2000,  0.2000,  0.6000,  1.0000]])\n",
    "        tensor([[-3.0002, -1.7882, -0.5763,  0.6357,  1.8476,  3.0002]])\n",
    "        '''\n",
    "        batch = x.shape[0]\n",
    "        x = torch.einsum('ij,k->ikj', x, torch.ones(self.out_dim, ).to(self.device)).reshape(batch, self.size).permute(1, 0)\n",
    "        x_pos = torch.sort(x, dim=1)[0]\n",
    "        y_eval = coef2curve(x_pos, self.grid, self.coef, self.k, device=self.device)\n",
    "        num_interval = self.grid.shape[1] - 1\n",
    "        ids = [int(batch / num_interval * i) for i in range(num_interval)] + [-1]\n",
    "        grid_adaptive = x_pos[:, ids]\n",
    "        margin = 0.01\n",
    "        grid_uniform = torch.cat([grid_adaptive[:, [0]] - margin + (grid_adaptive[:, [-1]] - grid_adaptive[:, [0]] + 2 * margin) * a for a in np.linspace(0, 1, num=self.grid.shape[1])], dim=1)\n",
    "        self.grid.data = self.grid_eps * grid_uniform + (1 - self.grid_eps) * grid_adaptive\n",
    "        self.coef.data = curve2coef(x_pos, y_eval, self.grid, self.k, device=self.device)\n",
    "\n",
    "    def initialize_grid_from_parent(self, parent, x):\n",
    "        '''\n",
    "        update grid from a parent KANLayer & samples\n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "            parent : KANLayer\n",
    "                a parent KANLayer (whose grid is usually coarser than the current model)\n",
    "            x : 2D torch.float\n",
    "                inputs, shape (number of samples, input dimension)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "            None\n",
    "          \n",
    "        Example\n",
    "        -------\n",
    "        >>> batch = 100\n",
    "        >>> parent_model = KANLayer(in_dim=1, out_dim=1, num=5, k=3)\n",
    "        >>> print(parent_model.grid.data)\n",
    "        >>> model = KANLayer(in_dim=1, out_dim=1, num=10, k=3)\n",
    "        >>> x = torch.normal(0,1,size=(batch, 1))\n",
    "        >>> model.initialize_grid_from_parent(parent_model, x)\n",
    "        >>> print(model.grid.data)\n",
    "        tensor([[-1.0000, -0.6000, -0.2000,  0.2000,  0.6000,  1.0000]])\n",
    "        tensor([[-1.0000, -0.8000, -0.6000, -0.4000, -0.2000,  0.0000,  0.2000,  0.4000,\n",
    "          0.6000,  0.8000,  1.0000]])\n",
    "        '''\n",
    "        batch = x.shape[0]\n",
    "        # preacts: shape (batch, in_dim) => shape (size, batch) (size = out_dim * in_dim)\n",
    "        x_eval = torch.einsum('ij,k->ikj', x, torch.ones(self.out_dim, ).to(self.device)).reshape(batch, self.size).permute(1, 0)\n",
    "        x_pos = parent.grid\n",
    "        sp2 = KANLayer(in_dim=1, out_dim=self.size, k=1, num=x_pos.shape[1] - 1, scale_base=0., device=self.device)\n",
    "        sp2.coef.data = curve2coef(sp2.grid, x_pos, sp2.grid, k=1, device=self.device)\n",
    "        y_eval = coef2curve(x_eval, parent.grid, parent.coef, parent.k, device=self.device)\n",
    "        percentile = torch.linspace(-1, 1, self.num + 1).to(self.device)\n",
    "        self.grid.data = sp2(percentile.unsqueeze(dim=1))[0].permute(1, 0)\n",
    "        self.coef.data = curve2coef(x_eval, y_eval, self.grid, self.k, self.device)\n",
    "\n",
    "    def get_subset(self, in_id, out_id):\n",
    "        '''\n",
    "        get a smaller KANLayer from a larger KANLayer (used for pruning)\n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "            in_id : list\n",
    "                id of selected input neurons\n",
    "            out_id : list\n",
    "                id of selected output neurons\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "            spb : KANLayer\n",
    "            \n",
    "        Example\n",
    "        -------\n",
    "        >>> kanlayer_large = KANLayer(in_dim=10, out_dim=10, num=5, k=3)\n",
    "        >>> kanlayer_small = kanlayer_large.get_subset([0,9],[1,2,3])\n",
    "        >>> kanlayer_small.in_dim, kanlayer_small.out_dim\n",
    "        (2, 3)\n",
    "        '''\n",
    "        spb = KANLayer(len(in_id), len(out_id), self.num, self.k, base_fun=self.base_fun, device=self.device)\n",
    "        spb.grid.data = self.grid.reshape(self.out_dim, self.in_dim, spb.num + 1)[out_id][:, in_id].reshape(-1, spb.num + 1)\n",
    "        spb.coef.data = self.coef.reshape(self.out_dim, self.in_dim, spb.coef.shape[1])[out_id][:, in_id].reshape(-1, spb.coef.shape[1])\n",
    "        spb.scale_base.data = self.scale_base.reshape(self.out_dim, self.in_dim)[out_id][:, in_id].reshape(-1, )\n",
    "        spb.scale_sp.data = self.scale_sp.reshape(self.out_dim, self.in_dim)[out_id][:, in_id].reshape(-1, )\n",
    "        spb.mask.data = self.mask.reshape(self.out_dim, self.in_dim)[out_id][:, in_id].reshape(-1, )\n",
    "\n",
    "        spb.in_dim = len(in_id)\n",
    "        spb.out_dim = len(out_id)\n",
    "        spb.size = spb.in_dim * spb.out_dim\n",
    "        return spb\n",
    "\n",
    "    def lock(self, ids):\n",
    "        '''\n",
    "        lock activation functions to share parameters based on ids\n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "            ids : list\n",
    "                list of ids of activation functions\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "            None\n",
    "          \n",
    "        Example\n",
    "        -------\n",
    "        >>> model = KANLayer(in_dim=3, out_dim=3, num=5, k=3)\n",
    "        >>> print(model.weight_sharing.reshape(3,3))\n",
    "        >>> model.lock([[0,0],[1,2],[2,1]]) # set (0,0),(1,2),(2,1) functions to be the same\n",
    "        >>> print(model.weight_sharing.reshape(3,3))\n",
    "        tensor([[0, 1, 2],\n",
    "                [3, 4, 5],\n",
    "                [6, 7, 8]])\n",
    "        tensor([[0, 1, 2],\n",
    "                [3, 4, 0],\n",
    "                [6, 0, 8]])\n",
    "        '''\n",
    "        self.lock_counter += 1\n",
    "        # ids: [[i1,j1],[i2,j2],[i3,j3],...]\n",
    "        for i in range(len(ids)):\n",
    "            if i != 0:\n",
    "                self.weight_sharing[ids[i][1] * self.in_dim + ids[i][0]] = ids[0][1] * self.in_dim + ids[0][0]\n",
    "            self.lock_id[ids[i][1] * self.in_dim + ids[i][0]] = self.lock_counter\n",
    "\n",
    "    def unlock(self, ids):\n",
    "        '''\n",
    "        unlock activation functions\n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "            ids : list\n",
    "                list of ids of activation functions\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "            None\n",
    "            \n",
    "        Example\n",
    "        -------\n",
    "        >>> model = KANLayer(in_dim=3, out_dim=3, num=5, k=3)\n",
    "        >>> model.lock([[0,0],[1,2],[2,1]]) # set (0,0),(1,2),(2,1) functions to be the same\n",
    "        >>> print(model.weight_sharing.reshape(3,3))\n",
    "        >>> model.unlock([[0,0],[1,2],[2,1]]) # unlock the locked functions\n",
    "        >>> print(model.weight_sharing.reshape(3,3))\n",
    "        tensor([[0, 1, 2],\n",
    "                [3, 4, 0],\n",
    "                [6, 0, 8]])\n",
    "        tensor([[0, 1, 2],\n",
    "                [3, 4, 5],\n",
    "                [6, 7, 8]])\n",
    "        '''\n",
    "        # check ids are locked\n",
    "        num = len(ids)\n",
    "        locked = True\n",
    "        for i in range(num):\n",
    "            locked *= (self.weight_sharing[ids[i][1] * self.in_dim + ids[i][0]] == self.weight_sharing[ids[0][1] * self.in_dim + ids[0][0]])\n",
    "        if locked == False:\n",
    "            print(\"they are not locked. unlock failed.\")\n",
    "            return 0\n",
    "        for i in range(len(ids)):\n",
    "            self.weight_sharing[ids[i][1] * self.in_dim + ids[i][0]] = ids[i][1] * self.in_dim + ids[i][0]\n",
    "            self.lock_id[ids[i][1] * self.in_dim + ids[i][0]] = 0\n",
    "        self.lock_counter -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNWithKANLayer(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNNWithKANLayer, self).__init__()\n",
    "        # Definiere die Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # Definiere die KANLayer\n",
    "        self.kanlayer = KANLayer(in_dim=64*8*8, out_dim=128, num=5, k=3, device='cpu')\n",
    "        \n",
    "        # Definiere die Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(128, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Forward through Convolutional Layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Flatten the output from Conv Layers\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        \n",
    "        # Forward through KANLayer\n",
    "        y, preacts, postacts, postspline = self.kanlayer(x)\n",
    "        \n",
    "        # Forward through Fully Connected Layers\n",
    "        x = F.relu(self.fc1(y))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    # Load and transform data\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616])\n",
    "    ])\n",
    "\n",
    "    num_workers = os.cpu_count() - 1\n",
    "\n",
    "    data_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(data_train, batch_size=config['training']['batch_size'], shuffle=True, num_workers=num_workers)\n",
    "\n",
    "    data_test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    test_loader = torch.utils.data.DataLoader(data_test, batch_size=config['training']['batch_size'], shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    # Initialize device\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Initialize model\n",
    "    model = CNNWithKANLayer(num_classes=10)\n",
    "    model.to(device)\n",
    "\n",
    "    # Set optimizer\n",
    "    optimizer_class = getattr(optim, config['training']['optimizer']['type'])\n",
    "    optimizer = optimizer_class(model.parameters(), **config['training']['optimizer']['parameters'])\n",
    "\n",
    "    # Set criterion\n",
    "    criterion_class = getattr(nn, config['training']['criterion']['type'])\n",
    "    criterion = criterion_class()\n",
    "\n",
    "    # Save epoch, loss and times\n",
    "    epochs = []\n",
    "    losses = []\n",
    "    times_epochs = []\n",
    "    total_training_time = 0.0\n",
    "\n",
    "    num_epochs = config['training']['num_epochs']\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epochs.append(epoch + 1)\n",
    "        losses.append(epoch_loss)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "        # Optional: Evaluate the model on the test set after each epoch\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Test Accuracy after epoch {epoch + 1}: {accuracy:.2f}%')\n",
    "\n",
    "    print('Training completed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
